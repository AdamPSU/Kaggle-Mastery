{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38f65e7-4001-4c56-83bf-9726f086dea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "import time \n",
    "\n",
    "from gc import collect\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm.callback import early_stopping, log_evaluation \n",
    "\n",
    "from model_info import get_model, fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e5640f-f821-469a-a14a-f0f87499f865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "LGB = True # Training LGB model, switch to pandas\n",
    "\n",
    "TARGET = \"responder_6\"\n",
    "WEIGHT = 'weight'\n",
    "\n",
    "FEATURES = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "FEATURES.append('symbol_id')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e937768-db24-4800-b981-58e2448492c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_path): \n",
    "    id_col = pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\") # Generate an id column\n",
    "    all_cols = pl.all() # Select all columns\n",
    "\n",
    "    # Read the parquet file and select the specified columns\n",
    "    data = pl.scan_parquet(file_path).select(id_col, all_cols)\n",
    "    \n",
    "    all_col_names = data.collect_schema().names()\n",
    "    \n",
    "    # Cols to not look for when classifying train and target column names\n",
    "    cols_of_disinterest = (\"weight\", \"id\", \"date_id\", \"time_id\", \"partition_id\")\n",
    "    target_columns, selected_columns = [], []\n",
    "\n",
    "    # Factory for loop to classify train and target column names\n",
    "    for col in all_col_names: \n",
    "        if col.startswith(\"responder\"):\n",
    "            target_columns.append(col)\n",
    "\n",
    "        elif not col.startswith(cols_of_disinterest):\n",
    "            selected_columns.append(col)\n",
    "            \n",
    "    data = data.collect()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35da025-1019-4242-aef1-3bc56c84e0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if TRAINING: \n",
    "    file_path = \"data/train.parquet\"\n",
    "\n",
    "    raw_data = load_data(file_path)\n",
    "\n",
    "    dates_to_skip = 500 # Too many missing stocks in the early days\n",
    "    num_test_dates = 100\n",
    "\n",
    "    # Filter the DataFrame to include only dates greater than or equal to dates_to_skip\n",
    "    raw_data = raw_data.filter(pl.col('date_id') >= dates_to_skip)\n",
    "            \n",
    "    # Get unique dates from the DataFrame\n",
    "    dates = raw_data['date_id'].unique()\n",
    "\n",
    "    # Define validation dates as the last `num_test_dates` dates\n",
    "    test_dates = dates[-num_test_dates:]\n",
    "\n",
    "    # Define training dates as all dates except the last `num_test_dates` dates\n",
    "    train_dates = dates[:-num_test_dates]\n",
    "    \n",
    "    # Prepare validation data for training\n",
    "    test_data = raw_data.filter(pl.col('date_id').is_in(test_dates))\n",
    "\n",
    "    X_test = test_data[FEATURES]\n",
    "    y_test = test_data[TARGET]\n",
    "    w_test = test_data[WEIGHT]\n",
    "    \n",
    "    # Training LGB model, must use numpy\n",
    "    if LGB: \n",
    "        X_test = test_data[FEATURES].to_numpy()\n",
    "        y_test = test_data[TARGET].to_numpy()\n",
    "        w_test = test_data[WEIGHT].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ae7fb9a-51f0-47c7-83d1-da0a517492c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'models/lgb_02'\n",
    "models, cv_scores = [], []\n",
    "\n",
    "def train(model, model_name):\n",
    "    # Not training, load `model_name` instead\n",
    "    if not TRAINING: \n",
    "        models.append(joblib.load(f'{model_path}/{model_name}_{i}.model'))\n",
    "        \n",
    "        return \n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Select dates for training based on the fold number\n",
    "    selected_dates = [date for ii, date in enumerate(train_dates) if ii % N_FOLDS != i]\n",
    "    \n",
    "    train_data = raw_data.filter(pl.col('date_id').is_in(train_dates))\n",
    "    \n",
    "    X_train = train_data[FEATURES]\n",
    "    y_train = train_data[TARGET]\n",
    "    w_train = train_data[WEIGHT]\n",
    "    \n",
    "    if model_name == 'xgb':\n",
    "        # Train XGBoost model with verbose logging\n",
    "        fit_model(model_name, model, X_test, y_test, w_train, w_test)\n",
    "        \n",
    "        cv_score = model.best_score\n",
    "    else: \n",
    "        # LGBM is incompatible with polars\n",
    "        X_train = X_train.to_numpy()\n",
    "        y_train = y_train.to_numpy()\n",
    "        w_train = w_train.to_numpy()\n",
    "    \n",
    "        # Train LightGBM model with early stopping and evaluation logging\n",
    "        model.fit(X_train, y_train, w_train,  \n",
    "                  eval_metric=[r2_lgb],\n",
    "                  eval_set=[(X_test, y_test, w_test)], \n",
    "                  callbacks=[\n",
    "                      early_stopping(30), \n",
    "                      log_evaluation(50)\n",
    "                  ])\n",
    "        \n",
    "        cv_score = model.best_score_['valid_0'][r2_lgb.__name__]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time \n",
    "    \n",
    "    print(f\"FOLD {i} COMPLETE, TIME: {time_elapsed:.3f}\")\n",
    "    \n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "    \n",
    "    del X_train, y_train, w_train\n",
    "    collect()\n",
    "\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model, f'{model_path}/{model_name}_{i}.model')\n",
    "    \n",
    "    return cv_score\n",
    "\n",
    "# Custom R2 metric for XGBoost\n",
    "def r2_xgb(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    \n",
    "    return -r2 # Must be negative for early stopping to work\n",
    "\n",
    "# Custom R2 metric for LightGBM\n",
    "def r2_lgb(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    \n",
    "    return 'r2', r2, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28d21b3f-e418-49a9-a0c9-08b7d3205a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.526039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19482\n",
      "[LightGBM] [Info] Number of data points in the train set: 35861029, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -0.002140\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's l2: 0.645387\tvalid_0's r2: 0.00454162\n",
      "[100]\tvalid_0's l2: 0.644597\tvalid_0's r2: 0.00575897\n",
      "[150]\tvalid_0's l2: 0.644253\tvalid_0's r2: 0.00629026\n",
      "[200]\tvalid_0's l2: 0.644059\tvalid_0's r2: 0.00658946\n",
      "[250]\tvalid_0's l2: 0.643921\tvalid_0's r2: 0.00680253\n",
      "[300]\tvalid_0's l2: 0.643844\tvalid_0's r2: 0.006921\n",
      "[350]\tvalid_0's l2: 0.643767\tvalid_0's r2: 0.00704041\n",
      "[400]\tvalid_0's l2: 0.643752\tvalid_0's r2: 0.0070622\n",
      "Early stopping, best iteration is:\n",
      "[385]\tvalid_0's l2: 0.643724\tvalid_0's r2: 0.00710665\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'r2_lgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(model_name)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, N_FOLDS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     cv_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     cv_scores\u001b[38;5;241m.\u001b[39mappend(cv_score)\n\u001b[1;32m      8\u001b[0m mean_cv_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cv_scores) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(cv_scores)\n",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, model_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Train LightGBM model with early stopping and evaluation logging\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, w_train,  \n\u001b[1;32m     35\u001b[0m               eval_metric\u001b[38;5;241m=\u001b[39m[r2_lgb],\n\u001b[1;32m     36\u001b[0m               eval_set\u001b[38;5;241m=\u001b[39m[(X_test, y_test, w_test)], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m                   log_evaluation(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     40\u001b[0m               ])\n\u001b[0;32m---> 42\u001b[0m     cv_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_score_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid_0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr2_lgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     45\u001b[0m time_elapsed \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time \n",
      "\u001b[0;31mKeyError\u001b[0m: 'r2_lgb'"
     ]
    }
   ],
   "source": [
    "model_name = 'lgb'\n",
    "model = get_model(model_name)\n",
    "\n",
    "for i in range(1, N_FOLDS+1):\n",
    "    cv_score = train(model, model_name)\n",
    "    cv_scores.append(cv_score)\n",
    "    \n",
    "mean_cv_score = sum(cv_scores) / len(cv_scores)\n",
    "print(f\"Mean CV Score: {mean_cv_score}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
