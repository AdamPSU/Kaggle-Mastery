{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38f65e7-4001-4c56-83bf-9726f086dea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "from gc import collect\n",
    "from pprint import pprint\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e5640f-f821-469a-a14a-f0f87499f865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING = True\n",
    "\n",
    "TARGET = \"responder_6\"\n",
    "WEIGHT = 'weight'\n",
    "FEATURES = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e937768-db24-4800-b981-58e2448492c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(file_path): \n",
    "    id_col = pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\") # Generate an id column\n",
    "    all_cols = pl.all() # Select all columns\n",
    "\n",
    "    # Read the parquet file and select the specified columns\n",
    "    data = pl.scan_parquet(file_path).select(id_col, all_cols)\n",
    "    \n",
    "    all_col_names = data.collect_schema().names()\n",
    "    \n",
    "    # Cols to not look for when classifying train and target column names\n",
    "    cols_of_disinterest = (\"weight\", \"id\", \"date_id\", \"time_id\", \"partition_id\")\n",
    "    target_columns, selected_columns = [], []\n",
    "\n",
    "    # Factory for loop to classify train and target column names\n",
    "    for col in all_col_names: \n",
    "        if col.startswith(\"responder\"):\n",
    "            target_columns.append(col)\n",
    "\n",
    "        elif not col.startswith(cols_of_disinterest):\n",
    "            selected_columns.append(col)\n",
    "            \n",
    "    data = data.collect()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35da025-1019-4242-aef1-3bc56c84e0e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 94)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>&hellip;</th><th>feature_52</th><th>feature_53</th><th>feature_54</th><th>feature_55</th><th>feature_56</th><th>feature_57</th><th>feature_58</th><th>feature_59</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>partition_id</th></tr><tr><td>u32</td><td>i16</td><td>i16</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i64</td></tr></thead><tbody><tr><td>7550157</td><td>500</td><td>0</td><td>1</td><td>4.372602</td><td>0.963079</td><td>0.84618</td><td>1.939234</td><td>1.16474</td><td>-3.205123</td><td>1.400332</td><td>1.898511</td><td>0.741687</td><td>-0.771141</td><td>11</td><td>7</td><td>76</td><td>-0.868997</td><td>0.425592</td><td>-0.567527</td><td>null</td><td>-0.190049</td><td>null</td><td>-1.571221</td><td>-1.437043</td><td>1.045398</td><td>null</td><td>2.7043</td><td>1.706279</td><td>0.158466</td><td>0.663829</td><td>null</td><td>null</td><td>1.811922</td><td>-0.342157</td><td>-0.454954</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.180584</td><td>null</td><td>-1.756384</td><td>1.894943</td><td>null</td><td>1.671203</td><td>0.640596</td><td>0.202007</td><td>-0.301725</td><td>-0.227596</td><td>-0.232882</td><td>-1.177839</td><td>-1.555593</td><td>-0.839841</td><td>0.338598</td><td>-0.424715</td><td>-1.003515</td><td>0.59359</td><td>-0.449099</td><td>null</td><td>null</td><td>-0.299348</td><td>-0.242119</td><td>-0.409873</td><td>-0.217973</td><td>-0.788824</td><td>-0.48744</td><td>-0.964526</td><td>-0.626286</td><td>-0.334997</td><td>-0.268242</td><td>-0.310255</td><td>-0.004007</td><td>0.286226</td><td>2</td></tr><tr><td>7550158</td><td>500</td><td>0</td><td>2</td><td>1.199431</td><td>0.999282</td><td>0.764294</td><td>1.495962</td><td>1.022274</td><td>-3.490678</td><td>2.477362</td><td>1.646399</td><td>0.750717</td><td>-0.850572</td><td>81</td><td>2</td><td>59</td><td>-1.189323</td><td>-0.369424</td><td>-0.490278</td><td>null</td><td>-0.423214</td><td>null</td><td>-1.497059</td><td>-1.589559</td><td>-0.578691</td><td>null</td><td>-0.466578</td><td>-0.832514</td><td>0.216229</td><td>-0.178512</td><td>null</td><td>null</td><td>0.522295</td><td>-0.337715</td><td>-0.75995</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.50654</td><td>null</td><td>-2.575124</td><td>2.466314</td><td>null</td><td>-0.942976</td><td>-0.517649</td><td>0.202007</td><td>0.30086</td><td>0.180316</td><td>0.457092</td><td>-1.667572</td><td>-1.902079</td><td>-1.052028</td><td>-0.368874</td><td>-0.689406</td><td>-0.665303</td><td>-0.233074</td><td>-0.753893</td><td>null</td><td>null</td><td>2.39499</td><td>1.658236</td><td>3.359613</td><td>3.601644</td><td>-0.291857</td><td>-0.329453</td><td>0.17402</td><td>0.122967</td><td>0.603747</td><td>0.371612</td><td>0.369653</td><td>0.823404</td><td>0.424229</td><td>2</td></tr><tr><td>7550159</td><td>500</td><td>0</td><td>3</td><td>0.689271</td><td>2.156528</td><td>0.379673</td><td>1.816525</td><td>1.40613</td><td>-2.788149</td><td>1.527157</td><td>1.377196</td><td>0.809322</td><td>-0.592266</td><td>4</td><td>3</td><td>11</td><td>-1.142846</td><td>0.255657</td><td>-0.589891</td><td>null</td><td>0.357676</td><td>null</td><td>-2.12926</td><td>-1.50641</td><td>-0.194643</td><td>null</td><td>-1.396933</td><td>-0.544472</td><td>0.455939</td><td>1.345349</td><td>null</td><td>null</td><td>-1.497517</td><td>-0.453106</td><td>-0.511397</td><td>null</td><td>&hellip;</td><td>null</td><td>null</td><td>-0.107985</td><td>null</td><td>-0.649515</td><td>1.734169</td><td>null</td><td>4.556169</td><td>1.784292</td><td>0.202007</td><td>-0.047826</td><td>-0.341877</td><td>-0.189566</td><td>null</td><td>null</td><td>-0.711492</td><td>0.055067</td><td>-0.587364</td><td>-1.103039</td><td>0.416081</td><td>-0.582688</td><td>null</td><td>null</td><td>1.390904</td><td>1.278604</td><td>0.061478</td><td>0.17966</td><td>-0.205636</td><td>-0.101051</td><td>-0.373885</td><td>0.610414</td><td>0.830006</td><td>-0.512456</td><td>0.776823</td><td>0.907171</td><td>-0.480423</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 94)\n",
       "┌─────────┬─────────┬─────────┬───────────┬───┬─────────────┬────────────┬────────────┬────────────┐\n",
       "│ id      ┆ date_id ┆ time_id ┆ symbol_id ┆ … ┆ responder_6 ┆ responder_ ┆ responder_ ┆ partition_ │\n",
       "│ ---     ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---         ┆ 7          ┆ 8          ┆ id         │\n",
       "│ u32     ┆ i16     ┆ i16     ┆ i8        ┆   ┆ f32         ┆ ---        ┆ ---        ┆ ---        │\n",
       "│         ┆         ┆         ┆           ┆   ┆             ┆ f32        ┆ f32        ┆ i64        │\n",
       "╞═════════╪═════════╪═════════╪═══════════╪═══╪═════════════╪════════════╪════════════╪════════════╡\n",
       "│ 7550157 ┆ 500     ┆ 0       ┆ 1         ┆ … ┆ -0.310255   ┆ -0.004007  ┆ 0.286226   ┆ 2          │\n",
       "│ 7550158 ┆ 500     ┆ 0       ┆ 2         ┆ … ┆ 0.369653    ┆ 0.823404   ┆ 0.424229   ┆ 2          │\n",
       "│ 7550159 ┆ 500     ┆ 0       ┆ 3         ┆ … ┆ 0.776823    ┆ 0.907171   ┆ -0.480423  ┆ 2          │\n",
       "└─────────┴─────────┴─────────┴───────────┴───┴─────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"data/train.parquet\"\n",
    "\n",
    "raw_data = load_data(file_path)\n",
    "\n",
    "dates_to_skip = 500\n",
    "num_test_dates = 100\n",
    "\n",
    "# Filter the DataFrame to include only dates greater than or equal to dates_to_skip\n",
    "raw_data = raw_data.filter(pl.col('date_id') >= dates_to_skip)\n",
    "\n",
    "# Get unique dates from the DataFrame\n",
    "dates = raw_data['date_id'].unique()\n",
    "\n",
    "# Define validation dates as the last `num_test_dates` dates\n",
    "test_dates = dates[-num_test_dates:]\n",
    "\n",
    "# Define training dates as all dates except the last `num_test_dates` dates\n",
    "train_dates = dates[:-num_test_dates]\n",
    "\n",
    "raw_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038dad21-0e63-4a92-bd43-ba2cc7cb3057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = raw_data.filter(pl.col('date_id').is_in(test_dates))\n",
    "\n",
    "# Prepare validation data for training\n",
    "if TRAINING: \n",
    "    X_test = test_data[FEATURES]\n",
    "    y_test = test_data[TARGET]\n",
    "    w_test = test_data[WEIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27b4b50-5c8d-48cc-a0bb-106dcfb51773",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = 'models/'\n",
    "models = []\n",
    "\n",
    "def train(model, model_name):\n",
    "    # Not training, load `model_name` instead\n",
    "    if not TRAINING: \n",
    "        models.append(joblib.load(f'{model_path}/{model_name}_{i}.model'))\n",
    "        \n",
    "        return \n",
    "    \n",
    "    # Select dates for training based on the fold number\n",
    "    selected_dates = [date for ii, date in enumerate(train_dates) if ii % N_FOLDS != i]\n",
    "    \n",
    "    train_data = raw_data.filter(pl.col('date_id').is_in(train_dates))\n",
    "    \n",
    "    X_train = train_data[FEATURES]\n",
    "    y_train = train_data[TARGET]\n",
    "    w_train = train_data[WEIGHT]\n",
    "        \n",
    "    # Train XGBoost model with verbose logging\n",
    "    model.fit(X_train, y_train, sample_weight=w_train, \n",
    "              eval_set=[(X_test, y_test)], \n",
    "              sample_weight_eval_set=[w_test], \n",
    "              verbose=50)\n",
    "    \n",
    "    # Append the trained model to the list\n",
    "    models.append(model)\n",
    "    \n",
    "    del X_train, y_train, w_train\n",
    "    collect()\n",
    "\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model, f'models/{model_name}_{i}.model')\n",
    "    \n",
    "    return \n",
    "\n",
    "# Custom R2 metric for XGBoost\n",
    "def r2_xgb(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    \n",
    "    return -r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d21b3f-e418-49a9-a0c9-08b7d3205a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-r2_xgb:-0.00073\n",
      "[50]\tvalidation_0-r2_xgb:-0.00603\n",
      "[100]\tvalidation_0-r2_xgb:-0.00651\n",
      "[150]\tvalidation_0-r2_xgb:-0.00667\n",
      "[200]\tvalidation_0-r2_xgb:-0.00638\n",
      "[249]\tvalidation_0-r2_xgb:-0.00583\n",
      "[0]\tvalidation_0-r2_xgb:-0.00073\n",
      "[50]\tvalidation_0-r2_xgb:-0.00603\n",
      "[100]\tvalidation_0-r2_xgb:-0.00651\n",
      "[150]\tvalidation_0-r2_xgb:-0.00667\n",
      "[200]\tvalidation_0-r2_xgb:-0.00638\n",
      "[250]\tvalidation_0-r2_xgb:-0.00582\n",
      "[0]\tvalidation_0-r2_xgb:-0.00073\n",
      "[50]\tvalidation_0-r2_xgb:-0.00603\n",
      "[100]\tvalidation_0-r2_xgb:-0.00651\n",
      "[150]\tvalidation_0-r2_xgb:-0.00667\n",
      "[200]\tvalidation_0-r2_xgb:-0.00638\n",
      "[250]\tvalidation_0-r2_xgb:-0.00582\n",
      "[0]\tvalidation_0-r2_xgb:-0.00073\n",
      "[50]\tvalidation_0-r2_xgb:-0.00603\n",
      "[100]\tvalidation_0-r2_xgb:-0.00651\n",
      "[150]\tvalidation_0-r2_xgb:-0.00667\n",
      "[200]\tvalidation_0-r2_xgb:-0.00638\n",
      "[249]\tvalidation_0-r2_xgb:-0.00583\n",
      "[0]\tvalidation_0-r2_xgb:-0.00073\n",
      "[50]\tvalidation_0-r2_xgb:-0.00603\n",
      "[100]\tvalidation_0-r2_xgb:-0.00651\n",
      "[150]\tvalidation_0-r2_xgb:-0.00667\n",
      "[200]\tvalidation_0-r2_xgb:-0.00638\n",
      "[250]\tvalidation_0-r2_xgb:-0.00582\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {'n_estimators': 2000,\n",
    "              'learning_rate': 0.1, \n",
    "              'max_depth': 6, \n",
    "              'tree_method': 'hist', \n",
    "              'objective': 'reg:squarederror',\n",
    "              'early_stopping_rounds': 100,\n",
    "              'eval_metric': r2_xgb,\n",
    "              'disable_default_eval_metric': True,\n",
    "              'device': 'cuda'}\n",
    "\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "for i in range(N_FOLDS):\n",
    "    train(xgb, 'xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0381ecb5-18c1-45f8-8279-cb771103fd41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
