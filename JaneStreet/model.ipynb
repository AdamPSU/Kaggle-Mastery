{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\nimport polars as pl\nimport pandas as pd\nimport numpy as np\nimport warnings; warnings.filterwarnings(action='ignore')\n\nfrom gc import collect\nfrom pprint import pprint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T03:33:45.921814Z","iopub.execute_input":"2024-10-24T03:33:45.922398Z","iopub.status.idle":"2024-10-24T03:33:46.818087Z","shell.execute_reply.started":"2024-10-24T03:33:45.922349Z","shell.execute_reply":"2024-10-24T03:33:46.816826Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"TARGET = \"responder_6\"\nFEATURES = [f\"feature_{i:02d}\" for i in range(79)]\n\nRANDOM_STATE = 42\nDEV_START_ID = 4_500_000\nVERSION_NUMBER  = \"V1_1\"","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:33:46.820642Z","iopub.execute_input":"2024-10-24T03:33:46.821319Z","iopub.status.idle":"2024-10-24T03:33:46.828765Z","shell.execute_reply.started":"2024-10-24T03:33:46.821261Z","shell.execute_reply":"2024-10-24T03:33:46.827540Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **DATA LOADING**\n\nHere, we load the data and describe the CV scheme. We don't need to specify the sub-directory paths while importing the datasets; polars knows to import all training components as this is a **hive** dataset. Specifying the train path is enough. Weights parameter is important here â€” this is a sample weight used in our custom eval-metric.\n","metadata":{}},{"cell_type":"code","source":"%%time \n\nid_col = pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\") # Generate an id column\nall_cols = pl.all() # Select all columns\n\n# Read the parquet file and select the specified columns\nfile_path = \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\"\ntrain = pl.scan_parquet(file_path).select(id_col, all_cols)\n\nall_col_names = train.collect_schema().names()\ncols_of_disinterest = (\"weight\", \"id\", \"date_id\", \"time_id\", \"partition_id\")\ntarget_columns, selected_columns = [], []\n\n# Factory for loop to classify train and target column names\nfor col in all_col_names: \n    if col.startswith(\"responder\"):\n        target_columns.append(col)\n        \n    elif not col.startswith(cols_of_disinterest):\n        selected_columns.append(col)\n        \nsample_weight = train.select(pl.col(\"weight\")).collect().to_series()\ncollect()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:33:46.830332Z","iopub.execute_input":"2024-10-24T03:33:46.830885Z","iopub.status.idle":"2024-10-24T03:33:47.496907Z","shell.execute_reply.started":"2024-10-24T03:33:46.830835Z","shell.execute_reply":"2024-10-24T03:33:47.495539Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"CPU times: user 256 ms, sys: 361 ms, total: 617 ms\nWall time: 647 ms\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"date_column = train.select(pl.col(\"date_id\")).collect()\n\ntrain_length = date_column.shape[0]\noffline_train_length = train_length - DEV_START_ID\nlast_train_date = date_column.row(offline_train_length)[0]\n\nprint(f\"Last offline train date = {last_train_date}\\n\")\n\ntrain_XY = train.filter(pl.col(\"date_id\").le(last_train_date))\ntest_XY = train.filter(pl.col(\"date_id\").gt(last_train_date))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:33:47.500248Z","iopub.execute_input":"2024-10-24T03:33:47.500790Z","iopub.status.idle":"2024-10-24T03:33:47.594932Z","shell.execute_reply.started":"2024-10-24T03:33:47.500732Z","shell.execute_reply":"2024-10-24T03:33:47.593610Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Last offline train date = 1577\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"train_data = train_XY.collect()\n#train_subset = train_data.limit(500_000).to_pandas()\n\n# del train_data\n# collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:40:42.279530Z","iopub.execute_input":"2024-10-24T03:40:42.281885Z","iopub.status.idle":"2024-10-24T03:41:36.014694Z","shell.execute_reply.started":"2024-10-24T03:40:42.281806Z","shell.execute_reply":"2024-10-24T03:41:36.013400Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def weighted_r2(y_true, y_pred, weight):\n    \"\"\"Custom Weighted R^2.\"\"\"\n    \n    weighted_r2 = 1 - np.sum(weight * (y_true - y_pred)**2) / np.sum(weight * y_true**2)\n    \n    return weighted_r2","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:16:53.667248Z","iopub.execute_input":"2024-10-24T03:16:53.667740Z","iopub.status.idle":"2024-10-24T03:16:53.674314Z","shell.execute_reply.started":"2024-10-24T03:16:53.667695Z","shell.execute_reply":"2024-10-24T03:16:53.672712Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# **FIT AND PREDICT**","metadata":{}},{"cell_type":"code","source":"train_data = train_subset\nweights = sample_weight.limit(500_000).to_pandas()\n\ntrain_data = train_data.fillna(0)\n\nX_train, y_train = train_data[FEATURES], train_data[TARGET]","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:18:02.249902Z","iopub.execute_input":"2024-10-24T03:18:02.251489Z","iopub.status.idle":"2024-10-24T03:18:02.883978Z","shell.execute_reply.started":"2024-10-24T03:18:02.251429Z","shell.execute_reply":"2024-10-24T03:18:02.882431Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nmodel = Ridge()\nmodel.fit(X_train, y_train)\n\ntrain_pred = model.predict(X_train)\ntest_pred = model.predict(X_test)\n\nprint(weighted_r2(y_train, train_pred, weights))\nprint(weighted_r2(y_test, test_pred, weights))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T03:18:31.292589Z","iopub.execute_input":"2024-10-24T03:18:31.293170Z","iopub.status.idle":"2024-10-24T03:18:32.244550Z","shell.execute_reply.started":"2024-10-24T03:18:31.293114Z","shell.execute_reply":"2024-10-24T03:18:32.241586Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.7242e-11): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n","output_type":"stream"},{"name":"stdout","text":"0.017258107662200928\n-0.008439421653747559\n","output_type":"stream"}]},{"cell_type":"code","source":"lags_ : pl.DataFrame | None = None\n\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each batch of predictions (except the very first) must be returned within 10 minutes of the batch features being provided.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n    # Use them as extra features, if you like.\n    global lags_\n    \n    if lags is not None:\n        lags_ = lags\n\n    # Predictions are clipped between -5 and 5.\n    predictions = test.select(\n        'row_id',\n        pl.lit(0.0).clip(-5, 5).alias('responder_6'),\n    )\n\n    # The predict function must return a DataFrame\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    # with columns 'row_id', 'responder_6'\n    assert predictions.columns == ['row_id', 'responder_6']\n    # and as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{},"execution_count":null,"outputs":[]}]}